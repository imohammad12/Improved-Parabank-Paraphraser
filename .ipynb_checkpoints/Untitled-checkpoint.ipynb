{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "finnish-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absent-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_pa\n",
    "\n",
    "stp_words = nltk.corpus.stopwords.words('english')\n",
    "sent = \"the great dark spot is thought to represent a hole in the methane cloud deck of neptune.\"\n",
    "sent_nopun = sent.translate(str.maketrans('', '', string.punctuation))\n",
    "par_neg = \"great dark the spot\"\n",
    "neg_const = par_neg.split(\" \")\n",
    "pos_const = ['the']\n",
    "for i in sent_nopun.split():\n",
    "    if i not in neg_const and i not in stp_words:\n",
    "        pos_const.append(i.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brilliant-calendar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the great dark spot is thought to represent a hole in the methane cloud deck of neptune.\\tgreat|dark|the|spot\\tthe|thought|represent|hole|methane|cloud|deck|neptune'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = sent + \"\\t\" + \"|\".join(neg_const) + '\\t' + \"|\".join(pos_const)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "overhead-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"inp.txt\", \"w\")\n",
    "f.write(inp)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bright-commitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO:sockeye.utils] Sockeye version 1.18.85, commit c1b1da8dc154a87cde0c41476eac2c7633fe6f9a, path /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/sockeye/__init__.py\r\n",
      "[INFO:sockeye.utils] MXNet version 1.7.0, path /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/mxnet/__init__.py\r\n",
      "[INFO:sockeye.utils] Command: /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/sockeye/translate.py -m . --json-input --output-type json --beam-size 20 --beam-prune 20 --batch-size 10 --device-ids 0 --disable-device-locking\r\n",
      "[INFO:sockeye.utils] Arguments: Namespace(avoid_list=None, batch_size=10, beam_prune=20.0, beam_search_stop='all', beam_size=20, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_ids=[0], disable_device_locking=True, ensemble_mode='linear', input=None, input_factors=None, json_input=True, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', max_input_len=None, max_output_length_num_stds=2, models=['.'], nbest_size=1, output=None, output_type='json', override_dtype=None, quiet=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=None, skip_topk=False, softmax_temperature=None, strip_unknown_words=False, sure_align_threshold=0.9, use_cpu=False)\r\n",
      "[INFO:sockeye.utils] Attempting to acquire 1 GPUs of 3 GPUs.\r\n",
      "[INFO:__main__] Translate Device: gpu(0)\r\n",
      "[INFO:sockeye.inference] Loading 1 model(s) from ['.'] ...\r\n",
      "[INFO:sockeye.vocab] Vocabulary (19581 words) loaded from \"./vocab.src.0.json\"\r\n",
      "[INFO:sockeye.vocab] Vocabulary (8 words) loaded from \"./vocab.src.1.json\"\r\n",
      "[INFO:sockeye.vocab] Vocabulary (6 words) loaded from \"./vocab.src.2.json\"\r\n",
      "[INFO:sockeye.vocab] Vocabulary (19581 words) loaded from \"./vocab.trg.0.json\"\r\n",
      "[INFO:sockeye.inference] Model version: 1.18.57\r\n",
      "[INFO:sockeye.model] ModelConfig loaded from \"./config\"\r\n",
      "[INFO:sockeye.inference] Disabling dropout layers for performance reasons\r\n",
      "[INFO:sockeye.model] Config[_frozen=True, config_data=Config[_frozen=True, data_statistics=Config[_frozen=True, average_len_target_per_bucket=[7.145073548898002, 13.99563686270617, 23.694915053093826, 33.6462227137744, 43.49996592832752, 53.29272556844158, 63.10734061789328, 72.93918370676286, 82.74942670991013, 91.22460162046973], buckets=[(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60), (70, 70), (80, 80), (90, 90), (100, 100)], length_ratio_mean=1.0442173528795242, length_ratio_std=0.22483564504779635, max_observed_len_source=100, max_observed_len_target=100, num_discarded=19307, num_sents=141362580, num_sents_per_bucket=[33253319, 53201168, 25616295, 13164610, 7278774, 4097681, 2341574, 1372938, 757906, 278315], num_tokens_source=2797831244, num_tokens_target=2903116929, num_unks_source=0, num_unks_target=0, size_vocab_source=19581, size_vocab_target=19581], max_seq_len_source=100, max_seq_len_target=100, num_source_factors=3, source_with_eos=True], config_decoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.0, dropout_attention=0.0, dropout_prepost=0.0, dtype=float32, feed_forward_num_hidden=2048, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=512, num_layers=6, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_embed_source=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=[Config[_frozen=False, num_embed=4, vocab_size=8], Config[_frozen=False, num_embed=4, vocab_size=6]], num_embed=512, num_factors=3, source_factors_combine=concat, vocab_size=19581], config_embed_target=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=None, num_embed=512, num_factors=1, source_factors_combine=concat, vocab_size=19581], config_encoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.0, dropout_attention=0.0, dropout_prepost=0.0, dtype=float32, feed_forward_num_hidden=2048, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=520, num_layers=6, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_loss=Config[_frozen=True, label_smoothing=0.1, name=cross-entropy, normalization_type=valid, vocab_size=19581], lhuc=False, vocab_source_size=19581, vocab_target_size=19581, weight_normalization=False, weight_tying=True, weight_tying_type=src_trg_softmax]\r\n",
      "[INFO:sockeye.encoder] sockeye.encoder.EncoderSequence dtype: float32\r\n",
      "[INFO:sockeye.encoder] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32\r\n",
      "[INFO:sockeye.encoder] sockeye.encoder.TransformerEncoder dtype: float32\r\n",
      "[INFO:sockeye.decoder] sockeye.decoder.TransformerDecoder dtype: float32\r\n",
      "[INFO:sockeye.encoder] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32\r\n",
      "[INFO:sockeye.model] Tying the source and target embeddings.\r\n",
      "[INFO:sockeye.model] Tying the target embeddings and output layer parameters.\r\n",
      "[INFO:sockeye.encoder] sockeye.encoder.Embedding dtype: float32\r\n",
      "[INFO:sockeye.encoder] sockeye.encoder.Embedding dtype: float32\r\n",
      "[INFO:sockeye.model] Loaded params from \"./params.best\"\r\n",
      "[INFO:sockeye.inference] 1 model(s) loaded in 2.5337s\r\n",
      "[INFO:sockeye.inference] Translator (1 model(s) beam_size=20 beam_prune=20.00 beam_search_stop=all nbest_size=1 ensemble_mode=None max_batch_size=10 buckets_source=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100] avoiding=0)\r\n",
      "[INFO:__main__] Translating...\r\n",
      "[WARNING:sockeye.inference] Overlap between constraints and avoid set, dropping the overlapping avoids\r\n",
      "[INFO:sockeye.inference] Input 1 has 8 constraints: the, thought, represent, hole, meth@@ ane, cloud, deck, ne@@ pt@@ une\r\n",
      "[INFO:__main__] Processed 1 lines. Total time: 20.0860, sec/sent: 20.0860, sent/sec: 0.0498\r\n",
      "A large black patch is thought to represent a hole in the methane cloud deck of neptune.\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ideal-swift",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO:sockeye.utils] Sockeye version 1.18.85, commit c1b1da8dc154a87cde0c41476eac2c7633fe6f9a, path /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/sockeye/__init__.py\n",
      "[INFO:sockeye.utils] MXNet version 1.7.0, path /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/mxnet/__init__.py\n",
      "[INFO:sockeye.utils] Command: /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/sockeye/translate.py -m . --json-input --output-type json --beam-size 20 --beam-prune 20 --batch-size 10 --device-ids 0 --disable-device-locking\n",
      "[INFO:sockeye.utils] Arguments: Namespace(avoid_list=None, batch_size=10, beam_prune=20.0, beam_search_stop='all', beam_size=20, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_ids=[0], disable_device_locking=True, ensemble_mode='linear', input=None, input_factors=None, json_input=True, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', max_input_len=None, max_output_length_num_stds=2, models=['.'], nbest_size=1, output=None, output_type='json', override_dtype=None, quiet=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=None, skip_topk=False, softmax_temperature=None, strip_unknown_words=False, sure_align_threshold=0.9, use_cpu=False)\n",
      "[INFO:sockeye.utils] Attempting to acquire 1 GPUs of 3 GPUs.\n",
      "[INFO:__main__] Translate Device: gpu(0)\n",
      "[INFO:sockeye.inference] Loading 1 model(s) from ['.'] ...\n",
      "[INFO:sockeye.vocab] Vocabulary (19581 words) loaded from \"./vocab.src.0.json\"\n",
      "[INFO:sockeye.vocab] Vocabulary (8 words) loaded from \"./vocab.src.1.json\"\n",
      "[INFO:sockeye.vocab] Vocabulary (6 words) loaded from \"./vocab.src.2.json\"\n",
      "[INFO:sockeye.vocab] Vocabulary (19581 words) loaded from \"./vocab.trg.0.json\"\n",
      "[INFO:sockeye.inference] Model version: 1.18.57\n",
      "[INFO:sockeye.model] ModelConfig loaded from \"./config\"\n",
      "[INFO:sockeye.inference] Disabling dropout layers for performance reasons\n",
      "[INFO:sockeye.model] Config[_frozen=True, config_data=Config[_frozen=True, data_statistics=Config[_frozen=True, average_len_target_per_bucket=[7.145073548898002, 13.99563686270617, 23.694915053093826, 33.6462227137744, 43.49996592832752, 53.29272556844158, 63.10734061789328, 72.93918370676286, 82.74942670991013, 91.22460162046973], buckets=[(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60), (70, 70), (80, 80), (90, 90), (100, 100)], length_ratio_mean=1.0442173528795242, length_ratio_std=0.22483564504779635, max_observed_len_source=100, max_observed_len_target=100, num_discarded=19307, num_sents=141362580, num_sents_per_bucket=[33253319, 53201168, 25616295, 13164610, 7278774, 4097681, 2341574, 1372938, 757906, 278315], num_tokens_source=2797831244, num_tokens_target=2903116929, num_unks_source=0, num_unks_target=0, size_vocab_source=19581, size_vocab_target=19581], max_seq_len_source=100, max_seq_len_target=100, num_source_factors=3, source_with_eos=True], config_decoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.0, dropout_attention=0.0, dropout_prepost=0.0, dtype=float32, feed_forward_num_hidden=2048, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=512, num_layers=6, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_embed_source=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=[Config[_frozen=False, num_embed=4, vocab_size=8], Config[_frozen=False, num_embed=4, vocab_size=6]], num_embed=512, num_factors=3, source_factors_combine=concat, vocab_size=19581], config_embed_target=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=None, num_embed=512, num_factors=1, source_factors_combine=concat, vocab_size=19581], config_encoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.0, dropout_attention=0.0, dropout_prepost=0.0, dtype=float32, feed_forward_num_hidden=2048, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=520, num_layers=6, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_loss=Config[_frozen=True, label_smoothing=0.1, name=cross-entropy, normalization_type=valid, vocab_size=19581], lhuc=False, vocab_source_size=19581, vocab_target_size=19581, weight_normalization=False, weight_tying=True, weight_tying_type=src_trg_softmax]\n",
      "[INFO:sockeye.encoder] sockeye.encoder.EncoderSequence dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.TransformerEncoder dtype: float32\n",
      "[INFO:sockeye.decoder] sockeye.decoder.TransformerDecoder dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32\n",
      "[INFO:sockeye.model] Tying the source and target embeddings.\n",
      "[INFO:sockeye.model] Tying the target embeddings and output layer parameters.\n",
      "[INFO:sockeye.encoder] sockeye.encoder.Embedding dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.Embedding dtype: float32\n",
      "[INFO:sockeye.model] Loaded params from \"./params.best\"\n",
      "[INFO:sockeye.inference] 1 model(s) loaded in 2.5321s\n",
      "[INFO:sockeye.inference] Translator (1 model(s) beam_size=20 beam_prune=20.00 beam_search_stop=all nbest_size=1 ensemble_mode=None max_batch_size=10 buckets_source=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100] avoiding=0)\n",
      "[INFO:__main__] Translating...\n",
      "[WARNING:sockeye.inference] Overlap between constraints and avoid set, dropping the overlapping avoids\n",
      "[INFO:sockeye.inference] Input 1 has 8 constraints: the, thought, represent, hole, meth@@ ane, cloud, deck, ne@@ pt@@ une\n",
      "[INFO:__main__] Processed 1 lines. Total time: 18.7913, sec/sent: 18.7913, sent/sec: 0.0532\n",
      "A large black patch is thought to represent a hole in the methane cloud deck of neptune.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./paraphrase.sh < ./inp.txt &> ./out.txt \n",
    "f = open(\"out.txt\", \"r\")\n",
    "print(f.read())\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "burning-weapon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A large black patch is thought to represent a hole in the methane cloud deck of neptune.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"out.txt\", \"r\")\n",
    "out = f.readable\n",
    "# print(f.read())\n",
    "# out\n",
    "f.readlines()[-1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "prepared-waterproof",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test. is|test this'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = sent + \" \" + \"|\".join(neg_const) + ' ' + \"|\".join(pos_const)\n",
    "# inp = \"This is a test.\\tis'|'test\\tthis\"\n",
    "# !echo -e \"This is a test.\\tis|test\\tthis\"\n",
    "# !echo -e {inp}\n",
    "inp \n",
    "# !echo -e {inp} | ./paraphrase.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "straight-rating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO:sockeye.utils] Sockeye version 1.18.85, commit c1b1da8dc154a87cde0c41476eac2c7633fe6f9a, path /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/sockeye/__init__.py\n",
      "[INFO:sockeye.utils] MXNet version 1.7.0, path /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/mxnet/__init__.py\n",
      "[INFO:sockeye.utils] Command: /home/m25dehgh/anaconda3/envs/IMR/lib/python3.8/site-packages/sockeye/translate.py -m . --json-input --output-type json --beam-size 20 --beam-prune 20 --batch-size 10 --device-ids 0 --disable-device-locking\n",
      "[INFO:sockeye.utils] Arguments: Namespace(avoid_list=None, batch_size=10, beam_prune=20.0, beam_search_stop='all', beam_size=20, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_ids=[0], disable_device_locking=True, ensemble_mode='linear', input=None, input_factors=None, json_input=True, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', max_input_len=None, max_output_length_num_stds=2, models=['.'], nbest_size=1, output=None, output_type='json', override_dtype=None, quiet=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=None, skip_topk=False, softmax_temperature=None, strip_unknown_words=False, sure_align_threshold=0.9, use_cpu=False)\n",
      "[INFO:sockeye.utils] Attempting to acquire 1 GPUs of 3 GPUs.\n",
      "[INFO:__main__] Translate Device: gpu(0)\n",
      "[INFO:sockeye.inference] Loading 1 model(s) from ['.'] ...\n",
      "[INFO:sockeye.vocab] Vocabulary (19581 words) loaded from \"./vocab.src.0.json\"\n",
      "[INFO:sockeye.vocab] Vocabulary (8 words) loaded from \"./vocab.src.1.json\"\n",
      "[INFO:sockeye.vocab] Vocabulary (6 words) loaded from \"./vocab.src.2.json\"\n",
      "[INFO:sockeye.vocab] Vocabulary (19581 words) loaded from \"./vocab.trg.0.json\"\n",
      "[INFO:sockeye.inference] Model version: 1.18.57\n",
      "[INFO:sockeye.model] ModelConfig loaded from \"./config\"\n",
      "[INFO:sockeye.inference] Disabling dropout layers for performance reasons\n",
      "[INFO:sockeye.model] Config[_frozen=True, config_data=Config[_frozen=True, data_statistics=Config[_frozen=True, average_len_target_per_bucket=[7.145073548898002, 13.99563686270617, 23.694915053093826, 33.6462227137744, 43.49996592832752, 53.29272556844158, 63.10734061789328, 72.93918370676286, 82.74942670991013, 91.22460162046973], buckets=[(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60), (70, 70), (80, 80), (90, 90), (100, 100)], length_ratio_mean=1.0442173528795242, length_ratio_std=0.22483564504779635, max_observed_len_source=100, max_observed_len_target=100, num_discarded=19307, num_sents=141362580, num_sents_per_bucket=[33253319, 53201168, 25616295, 13164610, 7278774, 4097681, 2341574, 1372938, 757906, 278315], num_tokens_source=2797831244, num_tokens_target=2903116929, num_unks_source=0, num_unks_target=0, size_vocab_source=19581, size_vocab_target=19581], max_seq_len_source=100, max_seq_len_target=100, num_source_factors=3, source_with_eos=True], config_decoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.0, dropout_attention=0.0, dropout_prepost=0.0, dtype=float32, feed_forward_num_hidden=2048, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=512, num_layers=6, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_embed_source=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=[Config[_frozen=False, num_embed=4, vocab_size=8], Config[_frozen=False, num_embed=4, vocab_size=6]], num_embed=512, num_factors=3, source_factors_combine=concat, vocab_size=19581], config_embed_target=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=None, num_embed=512, num_factors=1, source_factors_combine=concat, vocab_size=19581], config_encoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.0, dropout_attention=0.0, dropout_prepost=0.0, dtype=float32, feed_forward_num_hidden=2048, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=520, num_layers=6, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_loss=Config[_frozen=True, label_smoothing=0.1, name=cross-entropy, normalization_type=valid, vocab_size=19581], lhuc=False, vocab_source_size=19581, vocab_target_size=19581, weight_normalization=False, weight_tying=True, weight_tying_type=src_trg_softmax]\n",
      "[INFO:sockeye.encoder] sockeye.encoder.EncoderSequence dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.TransformerEncoder dtype: float32\n",
      "[INFO:sockeye.decoder] sockeye.decoder.TransformerDecoder dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32\n",
      "[INFO:sockeye.model] Tying the source and target embeddings.\n",
      "[INFO:sockeye.model] Tying the target embeddings and output layer parameters.\n",
      "[INFO:sockeye.encoder] sockeye.encoder.Embedding dtype: float32\n",
      "[INFO:sockeye.encoder] sockeye.encoder.Embedding dtype: float32\n",
      "[INFO:sockeye.model] Loaded params from \"./params.best\"\n",
      "[INFO:sockeye.inference] 1 model(s) loaded in 2.6725s\n",
      "[INFO:sockeye.inference] Translator (1 model(s) beam_size=20 beam_prune=20.00 beam_search_stop=all nbest_size=1 ensemble_mode=None max_batch_size=10 buckets_source=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100] avoiding=0)\n",
      "[INFO:__main__] Translating...\n",
      "[INFO:sockeye.inference] Input 1 has 1 constraint: this\n",
      "[INFO:__main__] Processed 1 lines. Total time: 6.7315, sec/sent: 6.7315, sent/sec: 0.1486\n",
      "It's a rehearsal, this one.\n"
     ]
    }
   ],
   "source": [
    "! echo -e \"This is a test.\\tis|test\\tthis\" | ./paraphrase.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cellular-excellence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test. is|test this\r\n"
     ]
    }
   ],
   "source": [
    "!echo -e $inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "african-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\tis|test\tthis|test\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"This is a test.\\tis'|'test\\tthis\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!echo -e \"This is a test.\\tis|test\\tthis|test\"\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "possible-detective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test. is|test this'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "palestinian-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -e {a[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "convenient-patrick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is a test.\\tis'|'test\\tthis\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bacterial-violence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-positive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMR",
   "language": "python",
   "name": "imr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
